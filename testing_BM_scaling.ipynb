{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d51eafcd-9d77-4282-89dc-50f9a73a2024",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 20:28:06.176089: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-20 20:28:06.176104: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-20 20:28:06.785819: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-20 20:28:06.785834: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-20 20:28:06.785844: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (rafael-ThinkPad): /proc/driver/nvidia/version does not exist\n",
      "2023-03-20 20:28:06.785984: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cirq\n",
    "from cirq.contrib.svg import SVGCircuit\n",
    "import random as rd\n",
    "from sympy import *\n",
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "import math\n",
    "import re\n",
    "import itertools\n",
    "from numpy import linalg as LA\n",
    "from scipy.stats import poisson\n",
    "import time\n",
    "from random import choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9998dc62-17c9-41f3-bae3-c4153c5c79bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_binary_strings(bit_count):\n",
    "    binary_strings = []\n",
    "    def genbin(n, bs=''):\n",
    "        if len(bs) == n:\n",
    "            binary_strings.append(bs)\n",
    "        else:\n",
    "            genbin(n, bs + '0')\n",
    "            genbin(n, bs + '1')\n",
    "\n",
    "    genbin(bit_count)\n",
    "    return binary_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9415cfa3-8047-4276-8e96-6fa6e9ec705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_by_k = {2 : 1, 3: 6.43, 4: 20.43, 5 : 45.7, 6: 70.21, 8: 176.54, 10: 708.92, 16: 45425.2}\n",
    "\n",
    "def generate_instance(k: int, n: int) -> np.ndarray:\n",
    "    #generate an instance of random k-SAT with n variables in the satisfiability threshold\n",
    "    if not (r := r_by_k.get(k)):\n",
    "        raise ValueError(f\"k must be in {list(r_by_k)} (got {k})\")\n",
    "    m = poisson(r*n).rvs()\n",
    "    #return np.random.choice(all_vars, size=(m, k))\n",
    "    all_variables = []\n",
    "    all_signs = []\n",
    "    for i in range(m):\n",
    "        #all_signs.append([rd.choice(l) for i in range(k)])\n",
    "        all_variables.append(choices(all_vars, k = k))\n",
    "\n",
    "    all_variables = np.array(all_variables)\n",
    "    #all_signs = np.array(all_signs)\n",
    "    return all_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eb92b63-5688-4560-8643-93f4c937580d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dimacs_writer(dimacs_filename, cnf_array):\n",
    "    #writes the dimacs file with the CNF\n",
    "    cnf = cnf_array\n",
    "    cnf_length = len(cnf)\n",
    "    n_sat = len(cnf[0])\n",
    "    var_num = np.max(cnf) \n",
    "    with open(dimacs_filename, \"w\") as f:\n",
    "\n",
    "        f.write('c DIMACS file CNF '+str(n_sat)+'-SAT \\n')\n",
    "        f.write(\"p cnf {} {}\\n\".format(var_num, cnf_length))\n",
    "        \n",
    "        for i, clause in enumerate(cnf):\n",
    "            line = clause.tolist()\n",
    "            if i == cnf_length - 1:\n",
    "                s = ' '.join(str(x) for x in line)+' 0'\n",
    "                f.write(s)\n",
    "            else: \n",
    "                s = ' '.join(str(x) for x in line)+' 0 \\n'\n",
    "                f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5b8ef90-bf9c-4185-a9bb-772f6bd6de6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Verifier():\n",
    "    #verifier from Qiskit page, takes a bit string and checks if cnf is satisfied\n",
    "    def __init__(self, dimacs_file):\n",
    "        with open(dimacs_file, 'r') as f:\n",
    "            self.dimacs = f.read()\n",
    "\n",
    "    def is_correct(self, guess):\n",
    "        guess = [bool(int(x)) for x in guess][::-1]\n",
    "        for line in self.dimacs.split('\\n'):\n",
    "            line = line.strip(' 0')\n",
    "            clause_eval = False\n",
    "            for literal in line.split(' '):\n",
    "                if literal in ['p', 'c']:\n",
    "                    # line is not a clause\n",
    "                    clause_eval = True\n",
    "                    break\n",
    "                if '-' in literal:\n",
    "                    literal = literal.strip('-')\n",
    "                    lit_eval = not guess[int(literal)-1]\n",
    "                else:\n",
    "                    lit_eval = guess[int(literal)-1]\n",
    "                clause_eval |= lit_eval\n",
    "            if clause_eval is False:\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eb43935-724b-486b-997e-484972d8041f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mixing_circuit(circuit, qubits, par):\n",
    "    for i in range(len(qubits)):\n",
    "        circuit.append(cirq.rx(par).on(qubits[i]))\n",
    "    return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4f42148-eb77-416d-b866-5fab0ddfddb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ham_layer(diagonal, circuit, qubits, par):\n",
    "    \n",
    "    l = cirq.DiagonalGate(diagonal)._decompose_(qubits)\n",
    "    l.pop(0)\n",
    "    for j, gate in enumerate(l):\n",
    "        #print(gate)\n",
    "        if j % 2 == 0:\n",
    "            dictn = gate._json_dict_()\n",
    "            my_string = str(dictn['gate'])\n",
    "            my_other_string = str(dictn['qubits'])\n",
    "            number_p = re.findall(\"\\d+\\.\\d+\", my_string)\n",
    "            res_p = [eval(i) for i in number_p]\n",
    "            \n",
    "            if '-' in my_string:\n",
    "                sign = -1\n",
    "            else:\n",
    "                sign = 1\n",
    "            \n",
    "            number_q = re.findall(r'\\d+', my_other_string)\n",
    "            res_q = [eval(i) for i in number_q]\n",
    "            rzgate = cirq.rz(sign*par*res_p[0]*np.pi).on(qubits[res_q[1]])\n",
    "            circuit.append(rzgate)\n",
    "        else:\n",
    "            circuit.append(gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a3b4bea-ddc1-4416-9522-b34a7d16fcff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyLRSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, initial_learning_rate):\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "\n",
    "    def __call__(self, step):\n",
    "        return self.initial_learning_rate / (step+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb5e71bc-7c77-4509-a84c-327437528f75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001110\n",
      "Time consumed in training:  158.8470904827118r) is 1.4531704187393188\n",
      "Time consumed in sampling:  0.17647576332092285\n",
      "011101\n",
      "Time consumed in training:  178.58337235450745) is 0.6702287197113037\n",
      "Time consumed in sampling:  0.2005157470703125\n",
      "011011\n",
      "Time consumed in training:  142.42836904525757) is 1.0685062408447266\n",
      "Time consumed in sampling:  0.12355351448059082\n",
      "000010\n",
      "Time consumed in training:  157.20101189613342) is 1.8307896852493286\n",
      "Time consumed in sampling:  0.22139286994934082\n",
      "111110\n",
      "Time consumed in training:  251.41383409500122) is 1.5015695095062256\n",
      "Time consumed in sampling:  0.12434124946594238\n",
      "001101\n",
      "Time consumed in training:  243.05299615859985) is 1.1702055931091309\n",
      "Time consumed in sampling:  0.12538647651672363\n",
      "110011\n",
      "111000\n",
      "Time consumed in training:  175.81706714630127) is 0.8358893990516663\n",
      "Time consumed in sampling:  0.13589835166931152\n",
      "100000\n",
      "Time consumed in training:  255.93854188919067) is 1.5930780172348022\n",
      "Time consumed in sampling:  0.1248788833618164\n",
      "010001\n",
      "Time consumed in training:  214.85955548286438) is 0.7941481471061707\n",
      "Time consumed in sampling:  0.22045421600341797\n",
      "011111\n",
      "111100\n",
      "Time consumed in training:  141.0246810913086r) is 0.7078253030776978\n",
      "Time consumed in sampling:  0.20159578323364258\n"
     ]
    }
   ],
   "source": [
    "k = 4 #length of clauses\n",
    "n_var = 6 #number of variables\n",
    "p = 6 #number of layers. When in doubt, stay on the lower side\n",
    "nqubits = n_var #number of qubits in the circuit\n",
    "\n",
    "all_vars = [i for i in range(-n_var,n_var+1)]\n",
    "all_vars = [i for i in all_vars if i != 0]\n",
    "binary_strings = generate_binary_strings(nqubits)\n",
    "times_list = []\n",
    "\n",
    "for _ in range(10):\n",
    "        \n",
    "    valid_keys = []\n",
    "    dimacs_filename = \"random_cnf_BM.dimacs\" \n",
    "\n",
    "    while not valid_keys:\n",
    "        #only accepts satisfiable CNFs\n",
    "        inst = generate_instance(k, n_var)\n",
    "        dimacs_writer(dimacs_filename, inst)\n",
    "        v = Verifier('random_cnf_BM.dimacs')\n",
    "\n",
    "        for key in binary_strings:\n",
    "            if v.is_correct(key) == True:\n",
    "                print(key) \n",
    "                valid_keys.append(key)\n",
    "\n",
    "    with open('random_cnf_BM.dimacs', 'r') as f:\n",
    "        dimacs = f.read()\n",
    "    #print(dimacs)\n",
    "    unsat_list = []\n",
    "\n",
    "    for key in binary_strings:\n",
    "        guess = [bool(int(x)) for x in key][::-1]\n",
    "\n",
    "        clause_eval_list = []\n",
    "        counter = 0\n",
    "        for j, line in enumerate(dimacs.split('\\n')):\n",
    "\n",
    "            line = line.strip(' 0')\n",
    "            clause_eval = False\n",
    "\n",
    "            for literal in line.split(' '):\n",
    "                if literal in ['p', 'c']:\n",
    "                    #line is not a clause\n",
    "                    clause_eval = True\n",
    "                    break\n",
    "                if '-' in literal:\n",
    "                    literal = literal.strip('-')\n",
    "                    lit_eval = not guess[int(literal)-1]\n",
    "                else:\n",
    "                    lit_eval = guess[int(literal)-1]\n",
    "                clause_eval |= lit_eval\n",
    "            #print(clause_eval)\n",
    "            if j > 1:\n",
    "                counter += 1\n",
    "                clause_eval_list.append(clause_eval)\n",
    "        unsat_clauses = counter - sum(clause_eval_list)\n",
    "        unsat_list.append(unsat_clauses)\n",
    "\n",
    "    diagonal = unsat_list\n",
    "\n",
    "    qubits = []\n",
    "\n",
    "    for i in range(nqubits):\n",
    "        qubits.append(cirq.GridQubit(0,i))        \n",
    "\n",
    "    qubits = list(qubits) #don't know why\n",
    "    all_qubits = [i for i in range(nqubits)]\n",
    "\n",
    "    def my_gate(c, index):\n",
    "        g = c * cirq.Z.on(qubits[index]) + cirq.I.on(qubits[index])\n",
    "        return g\n",
    "\n",
    "    x = [1, -1]\n",
    "    combinations = [p for p in itertools.product(x, repeat=nqubits)]\n",
    "\n",
    "    ops_list = []\n",
    "    for j, combination in enumerate(combinations):\n",
    "        ops_list.append((diagonal[j]/2**nqubits)*math.prod([my_gate(combination[i], i) for i in range(nqubits)]))\n",
    "\n",
    "    cost = np.sum(ops_list)\n",
    "\n",
    "    qaoa_circuit = cirq.Circuit()\n",
    "    num_param = 2 * p \n",
    "    parameters = symbols(\"q0:%d\" % num_param)\n",
    "\n",
    "    #setting up the layers\n",
    "    for i in range(p):\n",
    "        ham_layer(diagonal, qaoa_circuit, qubits, parameters[2 * i])\n",
    "        mixing_circuit(qaoa_circuit, qubits, parameters[2 * i + 1])\n",
    "\n",
    "    initial = cirq.Circuit()\n",
    "\n",
    "    for qubit in qubits:\n",
    "        initial.append(cirq.H(qubit)) #applying Hadamard to all qubits before running circuit\n",
    "\n",
    "    #setting up the model\n",
    "    lr = 1e-1\n",
    "\n",
    "    inputs = tfq.convert_to_tensor([initial])\n",
    "    ins = tf.keras.layers.Input(shape = (), dtype = tf.dtypes.string)\n",
    "    outs = tfq.layers.PQC(qaoa_circuit, cost)(ins)\n",
    "    ksat = tf.keras.models.Model(inputs = ins, outputs = outs)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=MyLRSchedule(lr))\n",
    "    ksat.trainable_variables[0].assign([0. for i in range(2*p)]) #initializing angles with some small noise\n",
    "\n",
    "    cost_m = cost.matrix()\n",
    "    gs_energy = np.real(min(LA.eig(cost_m)[0]))\n",
    "\n",
    "    losses = []\n",
    "    error = 1e2*rd.random()\n",
    "    tol = 1e-1\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    while _ < 1e6:\n",
    "        previous_error = error   \n",
    "        with tf.GradientTape() as tape:\n",
    "            error = ksat(inputs)\n",
    "\n",
    "        grads = tape.gradient(error, ksat.trainable_variables)\n",
    "        opt.apply_gradients(zip(grads, ksat.trainable_variables))\n",
    "        error = error.numpy()[0,0]\n",
    "        losses.append(error)\n",
    "\n",
    "        print('absolute value of (ground state energy - error) is ' + str(abs(gs_energy - error)), end = '\\r')\n",
    "\n",
    "        if abs(error - previous_error) < 1e-6:\n",
    "            #print('\\n got stuck!')\n",
    "            break\n",
    "\n",
    "    end = time.time()\n",
    "    time_training = end - start\n",
    "    print(\"Time consumed in training: \", end - start)\n",
    "    params = ksat.trainable_variables\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    sample_circuit = tfq.layers.AddCircuit()(inputs, append=qaoa_circuit)\n",
    "    output = tfq.layers.Sample()(sample_circuit, symbol_names=parameters, symbol_values=params, repetitions = 2048)\n",
    "\n",
    "    end = time.time()\n",
    "    time_sampling = end - start\n",
    "\n",
    "    times_list.append((time_training, time_sampling))\n",
    "\n",
    "    print(\"Time consumed in sampling: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42282b71-c73c-4b18-8c59-527dd2fc4b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     training  sampling\n",
      "0  158.847090  0.176476\n",
      "1  178.583372  0.200516\n",
      "2  142.428369  0.123554\n",
      "3  157.201012  0.221393\n",
      "4  251.413834  0.124341\n",
      "5  243.052996  0.125386\n",
      "6  175.817067  0.135898\n",
      "7  255.938542  0.124879\n",
      "8  214.859555  0.220454\n",
      "9  141.024681  0.201596\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame (times_list, columns = ['training', 'sampling'])\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62ac57f7-a77f-4c2c-b3a8-d48419ca029e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('times_k_'+str(k)+'_vars_'+str(n_var)+'_p_'+str(p)+'.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d5bbc86-f376-494f-99f8-ebe5effcf171",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca96b6d-789e-4a5a-8104-db537651ed50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
